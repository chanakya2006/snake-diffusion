{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from ddpm import DDPM\n",
    "import tqdm\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from old_unet import UNet\n",
    "from data import SequencesDataset\n",
    "from train import train\n",
    "import torchvision.transforms as transforms\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 1000\n",
    "\n",
    "T = 1000\n",
    "input_channels = 3\n",
    "context_length = 4\n",
    "actions_count = 5\n",
    "batch_size = 32\n",
    "num_workers = 2\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# For Mac OS\n",
    "if torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "\n",
    "# ROOT_PATH = \"../snake_agent/q_learning\"\n",
    "ROOT_PATH = \"./\"\n",
    "def local_path(path):\n",
    "    return os.path.join(ROOT_PATH, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddpm = DDPM(\n",
    "    T = T,\n",
    "    eps_model=UNet(\n",
    "        in_channels=input_channels * (context_length + 1),\n",
    "        out_channels=3,\n",
    "        T=T+1,\n",
    "        actions_count=actions_count,\n",
    "        seq_length=context_length\n",
    "    ),\n",
    "    context_length=context_length,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_to_tensor = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((.5,.5,.5), (.5,.5,.5))\n",
    "])\n",
    "\n",
    "dataset = SequencesDataset(\n",
    "    images_dir=local_path(\"snapshots\"),\n",
    "    actions_path=local_path(\"actions\"),\n",
    "    seq_length=context_length,\n",
    "    transform=transform_to_tensor\n",
    ")\n",
    "\n",
    "total_size = len(dataset)\n",
    "train_size = int(0.8 * total_size)  # 80% for training\n",
    "valid_size = total_size - train_size  # 20% for validation\n",
    "\n",
    "# Split the dataset\n",
    "train_dataset, val_dataset = random_split(\n",
    "    dataset, \n",
    "    [train_size, valid_size]\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/458 [00:13<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m _, val_losses \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mddpm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAdam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mddpm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2e-4\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataloader\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/ai-projects/snake-diffusion/diffusion/train.py:27\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, epochs, device, train_dataloader, val_dataloader)\u001b[0m\n\u001b[1;32m     24\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     26\u001b[0m imgs \u001b[38;5;241m=\u001b[39m imgs\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 27\u001b[0m previous_frames \u001b[38;5;241m=\u001b[39m \u001b[43mprevious_frames\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m(device)\n\u001b[1;32m     28\u001b[0m previous_actions \u001b[38;5;241m=\u001b[39m previous_actions\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     30\u001b[0m loss \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mforward(imgs, previous_frames, previous_actions)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "_, val_losses = train(\n",
    "    model=ddpm,\n",
    "    optimizer=torch.optim.Adam(params=ddpm.parameters(), lr=2e-4),\n",
    "    epochs=EPOCHS,\n",
    "    device=device,\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloader=val_dataloader,\n",
    "    save_every_epoch=100\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
